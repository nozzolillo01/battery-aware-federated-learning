# ðŸ”‹ Battery-Aware Federated Learning Framework

**A modular, extensible framework for energy-constrained federated learning research.**

Build and evaluate custom client selection strategies with realistic battery simulation for mobile and IoT federated learning scenarios. Designed for researchers who need flexibility, reproducibility, and production-grade code quality.

---

## ðŸŽ¯ Why This Framework?

Traditional federated learning assumes unlimited client availability. **Real-world IoT/mobile devices have battery constraints** that fundamentally change system dynamics:

- ðŸ“± **Energy heterogeneity**: Sensors, edge devices, and gateways have different consumption profiles
- ðŸ”‹ **Battery depletion**: Clients may die mid-training, wasting compute and bandwidth  
- âš¡ **Energy harvesting**: Solar/kinetic charging creates temporal participation patterns
- ðŸ“Š **Fairness challenges**: Low-power devices get excluded, causing model bias

**This framework lets you experiment with battery-aware selection policies** using a modular architecture that separates:
- **Client selection logic** (your algorithm)
- **Battery simulation** (realistic energy modeling)
- **FL strategy** (FedAvg, aggregation, metrics)

---

## âœ¨ Key Features

### ðŸ—ï¸ **Framework Architecture**
- **Pluggable selection strategies**: Swap algorithms without changing FL code
- **Strategy pattern implementation**: Clean separation of concerns
- **Type-safe interfaces**: Full Python type hints for IDE support
- **Production-ready**: Optimized, tested, and documented

### ðŸ”‹ **Battery Simulation**
- **Three device classes**: Low-power sensors, mid-range edge, high-power gateways
- **Realistic energy modeling**: Consumption scales with training epochs
- **Energy harvesting**: Time-proportional recharging (solar/kinetic simulation)
- **Death handling**: Automatic detection and removal of depleted clients

### ðŸ“Š **Built-in Observability**
- **Weights & Biases integration**: Automatic logging of all metrics
- **Per-client tracking**: Battery levels, selection probabilities, participation history
- **Round-level statistics**: Fairness (Jain index), energy consumption, eligible clients
- **Rich visualizations**: Ready-made charts for accuracy, loss, battery dynamics

### âš™ï¸ **Configuration-Driven**
- **Zero code changes**: All parameters in `pyproject.toml`
- **CLI overrides**: Test configurations without editing files
- **Multiple federations**: Predefined small/medium/large simulation setups
- **Reproducible**: Single source of truth for experimentsy-Aware Federated Learning

Federated Learning system with battery-aware client selection, designed for large-scale simulations in mobile/IoT scenarios. It includes a realistic battery simulator, selection strategies, rich logging to Weights & Biases (W&B), and full reproducibility from `pyproject.toml`.

## ðŸŒŸ What it does (at a glance)

- Battery-based client selection (weight âˆ battery_level^Î±, default Î±=2)
- Configurable minimum battery threshold for eligibility
- Realistic per-client consumption/charging simulation
- Complete metrics: client-side training/validation and centralized server-side test
- Ready-made W&B charts: â€œAccuracy per roundâ€ and â€œLoss per roundâ€

---

## ðŸ—ï¸ Framework Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flower Server                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FleetAwareFedAvg (Base Strategy)                      â”‚ â”‚
â”‚  â”‚  â€¢ Battery tracking                                     â”‚ â”‚
â”‚  â”‚  â€¢ Metrics aggregation                                  â”‚ â”‚
â”‚  â”‚  â€¢ W&B logging                                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚ uses                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ClientSelectionStrategy (Interface)                   â”‚ â”‚
â”‚  â”‚  â€¢ select_clients(eligible, available, fleet_manager)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚ implementations                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â–¼                   â–¼                     â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Random     â”‚   â”‚   Battery    â”‚    â”‚  Your Custom â”‚  â”‚
â”‚  â”‚   Baseline   â”‚   â”‚   Weighted   â”‚    â”‚   Strategy   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FleetManager                                          â”‚ â”‚
â”‚  â”‚  â€¢ Battery levels per client                           â”‚ â”‚
â”‚  â”‚  â€¢ Participation statistics                            â”‚ â”‚
â”‚  â”‚  â€¢ Fairness metrics (Jain index)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
app_battery/
â”œâ”€â”€ my_awesome_app/
â”‚   â”œâ”€â”€ task.py                    # ML task: CNN + CIFAR-10 + data partitioning
â”‚   â”œâ”€â”€ battery_simulator.py      # Battery physics + fleet management
â”‚   â”‚
â”‚   â”œâ”€â”€ selection/                 # ðŸ”Œ Selection strategies (pluggable)
â”‚   â”‚   â”œâ”€â”€ base.py               # ClientSelectionStrategy interface
â”‚   â”‚   â”œâ”€â”€ random_subset.py      # Baseline: uniform random
â”‚   â”‚   â””â”€â”€ battery_weighted.py   # Battery-aware probabilistic selection
â”‚   â”‚
â”‚   â”œâ”€â”€ strategies/                # Flower FedAvg implementations
â”‚   â”‚   â”œâ”€â”€ base.py               # FleetAwareFedAvg (common logic)
â”‚   â”‚   â”œâ”€â”€ random_client.py      # Random strategy wrapper
â”‚   â”‚   â””â”€â”€ battery_aware.py      # Battery strategy wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ client_app.py              # Flower ClientApp
â”‚   â”œâ”€â”€ server_app.py              # Flower ServerApp + strategy factory
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ pyproject.toml                 # Configuration + dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ EXAMPLES.md                    # Step-by-step extension tutorial
â””â”€â”€ CHANGES.md                     # Framework improvement history
```

**Design Principles:**
- ðŸ”Œ **Dependency Injection**: Strategies receive selection policy at construction
- ðŸŽ¯ **Single Responsibility**: Each module has one clear purpose
- ðŸ”„ **Open/Closed**: Extend via new strategies, don't modify base classes
- ðŸ“˜ **Interface Segregation**: Selection strategies implement minimal interface

## ðŸ§  Data and splits: what we actually measure

- Dataset: CIFARâ€‘10 from Hugging Face (`uoft-cs/cifar10`).
- Federated partitioning: Dirichlet with `alpha=0.1` (nonâ€‘IID) on the training data via `flwr_datasets.FederatedDataset`.
- Client-side validation: for each client, its shard is split `train/test` 80/20 (seed=42). Our â€œvalâ€ is therefore 20% of the clientâ€™s local training shard.
- Server-side test: centralized CIFARâ€‘10 â€œtestâ€ split (10,000 images) evaluated in `server_app.get_evaluate_fn`.

## â–¶ï¸ How to run

Requirements: Python 3.8+, pip. Optional: W&B account.

1) Install (recommended in a virtualenv)
```bash
python -m venv .venv
source .venv/bin/activate
pip install -e .
```

2) Start the simulation (uses `pyproject.toml` defaults)
```bash
flwr run .
```

## âš™ï¸ Configuration Parameters

All parameters are configured in `pyproject.toml` under `[tool.flwr.app.config]`:

### Training Parameters
- **`num-server-rounds`** (int): Number of federated learning rounds
- **`fraction-fit`** (float): Fraction of clients sampled by Flower's base FedAvg (typically 1.0)
- **`local-epochs`** (int): Number of local training epochs per client per round

### Client Selection Strategy
- **`strategy`** (int): Selection strategy to use
  - `0` = `random_baseline`: Uniform random selection (ignores battery)
  - `1` = `battery_aware`: Battery-weighted probabilistic selection

### Battery-Aware Selection Parameters (when `strategy=1`)
- **`sample-fraction`** (float, 0.0-1.0): Fraction of available clients to select per round
  - Example: With 200 clients and `sample-fraction=0.5`, selects 100 clients
  - Minimum 1 client always selected (if any available)
  - Default: `0.5` (50%)
  
- **`alpha`** (float, â‰¥0): Battery weight exponent for selection probability
  - Controls how strongly battery level influences selection
  - `alpha=1.0`: Linear weighting (mild preference for high battery)
  - `alpha=2.0`: Quadratic weighting (strong preference, **default**)
  - `alpha=3.0`: Cubic weighting (very strong preference)
  - Higher values = more aggressive battery-based selection
  
- **`min-battery-threshold`** (float, 0.0-1.0): Minimum battery level for participation
  - Clients below this threshold are excluded from selection
  - If no clients meet threshold, selects 2 clients with highest battery (fallback)
  - Default: `0.2` (20%)
  - Example: `0.0` = no minimum, `0.5` = only clients with â‰¥50% battery

### Device Classes
The simulator uses three device classes with different energy profiles:
- **`low_power_sensor`**: Low consumption (0.5-1.5%), low harvesting (0-1%)
- **`mid_edge_device`**: Medium consumption (2-3%), medium harvesting (0-2.5%)  
- **`high_power_gateway`**: High consumption (4-6%), high harvesting (0-5%)

### Federation Size
```toml
[tool.flwr.federations]
default = "small-simulation"

[tool.flwr.federations.small-simulation]
options.num-supernodes = 10

[tool.flwr.federations.medium-simulation]
options.num-supernodes = 50

[tool.flwr.federations.large-simulation]
options.num-supernodes = 200
```

### Running with Different Configurations

**Change federation size:**
```bash
flwr run . medium-simulation  # 50 clients
flwr run . large-simulation   # 200 clients
```

**Override parameters from CLI:**
```bash
flwr run . --run-config 'strategy=1 sample-fraction=0.3 alpha=3.0 num-server-rounds=25'
```

**Custom number of supernodes:**
```bash
flwr run . --num-supernodes 100
```

### Weights & Biases (W&B)
- **Enable**: Run `wandb login` for online charts
- **Disable**: Set `export WANDB_DISABLED=true`
- Note: `WANDB_SILENT=true` is set in code to reduce console noise

## ðŸ“Š Monitoring on W&B

Youâ€™ll find:
- chart/accuracy_per_round: train_accuracy_client, val_accuracy_client, test_accuracy_server
- chart/loss_per_round: train_loss_client, val_loss_client, test_loss_server
- Per-round tables with selection probabilities, battery levels, selected clients, deaths, etc.

Run names are `RANDOM_BASELINE-run-YYYY-mm-dd_HH:MM:SS` or `BATTERY_AWARE-run-...` depending on the strategy.

## ðŸ”§ How Battery-Aware Selection Works

When `strategy=1` (battery_aware), the selection process follows these steps:

1. **Filter eligible clients**: Only clients with `battery_level >= min-battery-threshold` are eligible
2. **Calculate weights**: Each eligible client gets weight = `battery_level^alpha`
3. **Normalize probabilities**: Convert weights to probabilities that sum to 1.0
4. **Sample clients**: Select `sample-fraction * available_clients` using weighted random sampling
5. **Remove depleted**: Clients without enough battery for training are removed
6. **Train survivors**: Remaining clients train and consume battery
7. **Recharge all**: All clients (selected or not) recharge via energy harvesting

**Key insight**: Higher `alpha` creates stronger preference for high-battery clients, while `sample-fraction` controls how many clients train per round.

## ðŸŽ¨ Extending the Framework

To add your own client selection strategy:

1. **Create selection policy** in `my_awesome_app/selection/`:
```python
from .base import ClientSelectionStrategy

class MyCustomSelection(ClientSelectionStrategy):
    def select_clients(self, eligible_clients, available_clients, 
                      fleet_manager=None, num_clients=None):
        # Your custom selection logic
        selected = ...  # List[ClientProxy]
        prob_map = {...}  # Dict[str, float]
        return selected, prob_map
```

2. **Create strategy** in `my_awesome_app/strategies/`:
```python
from .base import FleetAwareFedAvg
from ..selection import MyCustomSelection

class MyCustomStrategy(FleetAwareFedAvg):
    def __init__(self, *args, **kwargs):
        selection_strategy = MyCustomSelection()
        super().__init__(*args, selection_strategy=selection_strategy,
                        strategy_name="my_custom", **kwargs)
```

3. **Register in server_app.py** and add to config options

ðŸ“˜ **See [EXAMPLES.md](EXAMPLES.md) for complete step-by-step tutorial with code examples!**

## ï¿½ Recent Changes

See [CHANGES.md](CHANGES.md) for a detailed summary of framework improvements including:
- Configurable `sample-fraction` parameter
- Comprehensive parameter documentation
- Descriptive device class names
- Complete custom strategy tutorial

## ï¿½ðŸ“„ License

Apacheâ€‘2.0. See `LICENSE`.

## ðŸ”¨ Stack

- [Flower](https://flower.ai/) â€¢ [PyTorch](https://pytorch.org/) â€¢ [flwr-datasets](https://github.com/adap/flower/tree/main/baselines/flwr_datasets) â€¢ [Weights & Biases](https://wandb.ai/) â€¢ CIFARâ€‘10

â€”

Optimized for experimenting with energyâ€‘aware federated learning strategies with clear metrics and reproducibility.